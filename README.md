# Deep Learning Repository

A comprehensive collection of deep learning implementations, research papers, and educational resources.

## Repository Structure

### Core Implementations
- **Computer Vision**: CNN architectures, Vision Transformers, YOLO object detection
- **RNNs**: Bidirectional RNNs, Deep RNNs, Encoder-Decoder architectures
- **Transformers**: GPT implementations, self-attention mechanisms
- **GPT-2**: Complete GPT-2 implementation from scratch
- **Tokenizers**: BPE tokenization in Python and C++

### Educational Resources
- **Papers**: Collection of foundational research papers organized by domain
- **Paper Notes**: Summaries and analysis of key papers
- **Projects**: Complete end-to-end applications and experiments

### Specific Implementations

#### Computer Vision
- **CNNs**: AlexNet, ResNet, LeNet, GoogleNet, MobileNet, VGG
- **ViT**: Vision Transformer for image classification
- **YOLO**: Real-time object detection (YOLO v1)

#### Natural Language Processing
- **GPT-2**: Generative Pre-trained Transformer implementation
- **Transformers**: Educational GPT implementation with attention visualization
- **RNNs**: Bidirectional and deep recurrent networks
- **Tokenizers**: Byte Pair Encoding for subword tokenization

#### Sequence Models
- **Encoder-Decoder**: Sequence-to-sequence learning
- **Attention Mechanisms**: Self-attention and multi-head attention
- **LSTM/GRU**: Advanced recurrent architectures

## Key Features

- **From Scratch Implementations**: All models implemented from first principles
- **Educational Focus**: Clear, well-documented code for learning
- **Paper Integration**: Code implementations paired with research papers
- **Multiple Domains**: Computer vision, NLP, and sequence modeling
- **Performance Optimized**: Both Python and C++ implementations where applicable

## Getting Started

Each directory contains its own README with specific instructions. Start with:

1. **Computer Vision/CNNs** for convolutional neural networks
2. **Transformers** for attention mechanisms and modern architectures
3. **Papers** for theoretical background and research papers
4. **Projects** for complete applications and experiments

## Research Papers Included

The repository includes implementations based on these foundational papers:
- Attention Is All You Need (Transformers)
- Deep Residual Learning for Image Recognition (ResNet)
- ImageNet Classification with Deep CNNs (AlexNet)
- You Only Look Once: Real-Time Object Detection (YOLO)
- Long Short-Term Memory (LSTM)
- And many more in the Papers directory

Made by **smruti**

